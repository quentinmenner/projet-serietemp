---
title: "Projet séries temporelles linéaires"
author: Antoine Joubrel et Quentin Menner
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document:
    toc: true
    toc_depth: 2
geometry: left=1.5cm,right=1.5cm,top=2cm,bottom=2cm
classoption: landscape
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(patchwork)
```

##  Partie I : Les données

### Question 1

La série étudiée représente la production mensuelle de biens manufacturés en France métropolitaine entre janvier 1985 et janvier 2000. C'est une série agrégée corrigée des variations saisonnières et des jours ouvrés (CVS-CJO) contenant 181 observations. L'unité de mesure est un indice de base 100 en 1990.
La série est de la forme suivante :

### Question 2

a) Nous sommes d'abord demandés si la série avait une saisonnalité. En observant attentivement année après année, on pourrait croire que la série est globalement croissante sur une année. Pour en avoir le coeur nette, nous avons regardé la répartition de l'indice pour chaque mois.

```{r, include=TRUE, echo=FALSE}
lien_graph = "Graphiques"
gg3 = readRDS(file.path(lien_graph,"boxplot.rds"))
plot(gg3)

```

Aucune saisonnalité semble se dégager.

b) Toutefois la série possède une tendance nette à la hausse malgré une baisse de l'indice entre 1990 et 1994. 

```{r, include=TRUE, echo=FALSE}
lien_graph = "Graphiques"
gg = readRDS(file.path(lien_graph,"courbe.rds"))
plot(gg)

```

Elle est nette quand on réalise une régression linéaire de la série sur le temps (coefficent de 0.087).

Nous avons donc différencié la série puis réaliser des tests de stationnarité sur cette nouvelle série.

Les test ADF et PP rejète l'hypothèse de racine unité et le test KPSS ne rejette pas l'hypothèse de stationnarité de la série. Nous considérons donc la série différenciée statinnaire.

### Question 3

```{r, include=TRUE, echo=FALSE}
lien_graph = "Graphiques"
gg = readRDS(file.path(lien_graph,"courbe.rds"))
gg_diff = readRDS(file.path(lien_graph,"ts_choisie.rds"))

gg

gg_diff
```

## Partie II : Modèles ARMA

### Question 4

Une caractéristique importante de notre série temporelle est l'autocorrélation des résidues. On observe en effet qu'ils sont linéairement décroissants et en dehors des intervalles de confiance comme il est le cas dans un AR pure. Nous sommes donc amèné à penser que la série est un AR pure.

```{r, include=TRUE, echo=FALSE}

acf1 = readRDS(file.path(lien_graph,"ACF_1.rds"))
plot(acf1)

```

Continuous tout de même la méthode de Box-Jenkins, pour voir si notre hypothèse est vérifiée.

Les graphiques de l'ACF et du PACF donne comme valeur maximale des coeffecients AR et MA 1.

```{r, include=TRUE, echo=FALSE}

acf = readRDS(file.path(lien_graph,"ACF_ts_choix.rds"))
pacf = readRDS(file.path(lien_graph,"PACF_ts_choix.rds"))
acf/
  pacf

```

On évalue donc 4 modèles : ARMA(0,0), ARMA(1,0) (ou AR(1)), ARMA(0,1) (ou MA(1)) et ARMA(1,1) en regardant d'abord l'autocorrélation des résidues et la significativité des coefficients.

- Pour le modèle ARMA(0,0) (bruit blanc)
```{r, include=TRUE, echo=FALSE}
library(knitr)
models_evalues = readRDS("eval_modele.rds")

broom::tidy(models_evalues[[1]]$ttest)
```

La constante (seul paramètre) n'est pas significative.

```{r, include=TRUE, echo=FALSE}
library(knitr)

head(models_evalues[[1]]$lbtest, 10)
```

En revanche, les résidues ne sont pas du tout autocorélées. **On ne retient pas ce modèle**.

- De même pour le modèle AR(1)
```{r, include=TRUE, echo=FALSE}
broom::tidy(models_evalues[[2]]$ttest)
```

Les coefficients sont significatifs aux seuils usuels.

```{r, include=TRUE, echo=FALSE}
head(models_evalues[[2]]$lbtest, 15)
```

Globalement, les résidus ne sont pas corrélés entre eux (à part pour l'ordre 5). Donc **le modèle AR(1) est retenu.**

De même le modèle MA(1) est retenu car les résidus sont encore moins autocorrélés et les coefficients sont significatifs. Toutefois le modèles ARMA(1,1) n'est pas retenu car les coeffcients ne sont pas tous significatfs.

Pour départager le modèle AR(1) et MA(1) nous avons comparé les critères d'informations (AIC et BIC) qui montre que le modèle AR(1) est meilleur.

Est-il valide ? Pour cela, nous avons observé la répartition des résidus.
```{r, include=TRUE, echo=FALSE}
library(forecast)
model = readRDS('model_est.rds')
checkresiduals(model)
```

### Question 5

Nous supposons que donc la production mensuelle de biens manufacturés suit un **ARIMA(1,1,0)** car la série avait besoin d'être différencié une fois pour être stationnaire.
Le coeffcients lié à l'AR(1) est estimé à **-0.388** et la constante est de **0.134**. La formule de la série est donc :

$$
X_t = 0.134 + 0.612X_{t-1} + 0.388X_{t-2} + \epsilon_t
$$
avec $\epsilon_t$ un bruit blanc gaussien.

## Partie III : Prévision

6. Comme nous avons réalisé une différentiation d'un mois à l'autre dans la question 2, nous prenons ici le modèle AR(1) de la forme suivante :
\begin{align*}
\Delta X_{t+1} &= a_{0} \Delta X_{t} + \epsilon_{t} \\
X_{t+1} &= (a_{0}+1)X_{t} - a_{0}X_{t-1} + \epsilon_{t}
\end{align*}
Avec $(\epsilon_{t})_{t} \sim {\sf Norm}(0,1)$. Avec une probabilité de $\alpha\%$, $q_{\frac{\alpha}{2}} \leq \mid\epsilon_{t}\mid \leq q_{1-\frac{\alpha}{2}}$. Ce qui donne :

\begin{align*}
q_{\frac{\alpha}{2}} + (a_{0}+1)X_{T} - a_{0}X_{T-1} \leq &X_{T+1} \leq q_{1-\frac{\alpha}{2}} + (a_{0}+1)X_{T} - a_{0}X_{T-1} \\ \\

\text{Et : } q_{\frac{\alpha}{2}} + (a_{0}+1)X_{T+1} - a_{0}X_{T} \leq &X_{T+2} \leq q_{1-\frac{\alpha}{2}} + (a_{0}+1)X_{T+1} - a_{0}X_{T} \\

q_{\frac{\alpha}{2}} + (a_{0}+1)(q_{\frac{\alpha}{2}} + (a_{0}+1)X_{T} - a_{0}X_{T-1}) - a_{0}X_{T} \leq &X_{T+2} \leq q_{1-\frac{\alpha}{2}} + (a_{0}+1)(q_{1-\frac{\alpha}{2}} + (a_{0}+1)X_{T} - a_{0}X_{T-1}) - a_{0}X_{T} \\

(a_{0}+2)q_{\frac{\alpha}{2}} + (a_{0}^2+a_{0}+1)X_{T} - a_{0}(a_{0}+1)X_{T-1} \leq &X_{T+2} \leq (a_{0}+2)q_{1-\frac{\alpha}{2}} + (a_{0}^2+a_{0}+1)X_{T} - a_{0}(a_{0}+1)X_{T-1} \\

\end{align*}

D'après la partie II, $a_{0} = -0,388$. Donc on a comme région de confiance de niveau $\alpha$:

$X_{T+1} \in \left[q_{\frac{\alpha}{2}} + 0.612X_{T} + 0.388X_{T-1}, q_{1-\frac{\alpha}{2}} + 0.612X_{T} + 0.388X_{T-1}\right]$

$X_{T+2} \in \left[1.612q_{\frac{\alpha}{2}} + 0.762544X_{T} + 0.237456X_{T-1}, 1.612q_{1-\frac{\alpha}{2}} + 0.762544X_{T} + 0.237456X_{T-1}\right]$

7. Pour obtenir cette région de confiance, nous utilisons les hypothèses que les résidus suivent une loi normale centrée réduite, que la série temporelle est considérée comme stationnaire une fois la différenciation effectuée et qu'elle peut être modélisée par un modèle ARIMA de paramètres (1,1,0)

8. On prend ici une région de confiance de niveau 95%. Donc $q_{2.5}=-1.96$ et $q_{97.5}=1.96$. On considère T et T-1 comme étant respectivement la dernière et l'avant-dernière période de notre série temporelle ce qui donne $X_{T}=112.3$ et $X_{T-1}=112.6$. Donc $X_{T+1} \in \left[110.4564,114.3764\right]$ et 
$X_{T+2} \in \left[41.6124 - 0.612X_{T+1},45.5324 - 0.612X_{T+1}\right]$

Cela nous donne la région de confiance suivante pour $X_{T+2}$ en fonction de $X_{T+1}$ :

9. On cherche à déterminer une méthode permettant de prédire à $X_{T+1}$ à partir d'une autre série $(Y_{t})_{1 \leq t \leq T+1}$ et plus précisément de sa valeur à la T+1ème période $Y_{T+1}$.

On sait que $(Y_{t})_{1 \leq t \leq T+1}$ est une série stationnaire. De même dans notre cas, $(\Delta X_{t})_{t}$ est aussi stationnaire. Comme on considère que l'on a $Y_{T+1}$ avant $X_{T+1}$, on peut donc réaliser la régression suivante : 
\begin{align*}
\Delta X_{T+1} &= \beta Y_{T+1} + c + u_{t} \\
X_{T+1} &= \beta Y_{T+1} + X_{T} + c + u_{t} \\
\text{Avec : }\beta &= \frac{Cov(X_{t},Y_{t})}{Var(X_{t})} \\
\text{et }c &= EY_{t}-\beta EX_{t} \\
\end{align*}
Pour pouvoir réaliser cette régression il faut s'assurer que la condition suivante est respectée :
\begin{align*}
\beta &\neq 0 \\
\text{Soit : }Cov(X_{t},Y_{t}) &\neq 0 \\
\end{align*}
On doit en plus considérer comme condition que les observations sont comme un échantillon donc que l'écart type estimé de $\hat{\beta}_{n}$ notée $se_{n}$ est juste ce qui ne serait pas le cas normalement.
Dans ce cas, on peut réaliser un test de $H_{0} : \beta = 0$ contre $H_{1} : \beta \neq 0$.
Pour tester $H_{0}$ au niveau $\alpha$, nous considérons la t-statistique $t_{n}=\frac{\hat{\beta}_{n}}{se_{n}}$ et la région critique :
$W_{\alpha}=\{\mid t_{j} \mid > q_{1-\frac{\alpha}{2}}\},$
où $q_{1-\frac{\alpha}{2}}$ est le quantile d'ordre $1-\frac{\alpha}{2}$ de $N(0,1)$.